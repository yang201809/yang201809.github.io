[{"title":"8个常用的python办公室自动化技巧","url":"/2023/12/03/8%E4%B8%AA%E5%B8%B8%E7%94%A8%E7%9A%84python%E5%8A%9E%E5%85%AC%E5%AE%A4%E8%87%AA%E5%8A%A8%E5%8C%96%E6%8A%80%E5%B7%A7/","content":"本文就给大家介绍几个我用到的办公室自动化技巧:\n1 Word文档doc转docx想用python-docx 读取word文件中的数据, 但是python-docx只支持docx格式, 所以研究了这两种格式的转换。\n1.1 导入工具包 \nimport osfrom win32com import client as wc\n1.2 获取文件夹下面所有doc文件明细\n# 路径path=&quot;C:/Users/yyz/Desktop/python办公技巧/data/doc转docx/&quot;   # 根据自己电脑文件修改# 定义空list,存放文件绝对路径files = []for file in os.listdir(path):    if file.endswith(&quot;.doc&quot;):        files.append(path+file)files\n\n1.3 转换文件\n# 运行word程序word = wc.Dispatch(&quot;Word.Application&quot;)# for循环i = 0for file in files:    try:        doc = word.Documents.Open(file)    #打开word文件        doc.SaveAs(&quot;&#123;&#125;x&quot;.format(file), 12)   #另存为后缀为&quot;.docx&quot;的文件，其中参数12指docx文件        doc.Close()  #关闭原来word文件        print(file +&#x27;:转换成功&#x27;)        i +=1    except:        print(file +&#x27;:转换[不成功]&#x27;)           files.append(file)  # 若读取文件报错, 则将文件名称添加到files列表中重新读取        passprint(&#x27;转换文件%i个&#x27;%i)    # 退出word    word.Quit()\n2 文字地址批量转经纬度工作中地址转经纬度会用在做地图可视化或者计算距离方面。\n2.1 导入工具包\n# 导入工具包import pandas as pdimport jsonfrom urllib.request import urlopen, quoteimport requests\n2.2 定义转换函数\n# 定义函数def getlnglat(address):    url = &#x27;http://api.map.baidu.com/geocoding/v3/&#x27;    output = &#x27;json&#x27;    ak = &quot;自己申请的api&quot;   # 百度地图API, 需要自己申请    address = quote(address) # 由于本文地址变量为中文，为防止乱码，先用quote进行编码    uri = url + &#x27;?&#x27; + &#x27;address=&#x27; + address  + &#x27;&amp;output=&#x27; + output + &#x27;&amp;ak=&#x27; + ak  +&#x27;&amp;callback=showLocation%20&#x27;+&#x27;//GET%E8%AF%B7%E6%B1%82&#x27;    res=requests.get(uri).text    temp = json.loads(res) # 将字符串转化为json    lat = temp[&#x27;result&#x27;][&#x27;location&#x27;][&#x27;lat&#x27;]    lng = temp[&#x27;result&#x27;][&#x27;location&#x27;][&#x27;lng&#x27;]    return lng, lat   # 经度 longitude,纬度 latitude,\n2.3 地址转换2.3.1 单个地址转换\n# 单个地址转换getlnglat(&#x27;北京市朝阳区高碑店地区办事处高井村委会&#x27;)(116.52784003604923, 39.91806508560947)\n2.3.2 批量地址转换\n# 读取数据data = pd.read_excel(&#x27;C:/Users/yyz/Desktop/python办公技巧/data/地址信息.xlsx&#x27;)data\n\n\ndata[&#x27;经度&#x27;] = &#x27;&#x27;data[&#x27;纬度&#x27;] = &#x27;&#x27;for i in range(data.shape[0]):    try:        data.iloc[i,2] = getlnglat(data.iloc[i,1])[0] # 经度 将第i行,第2列的地址(列索引为1)转换为经纬度,并将经度赋值给第i行,第3列(列索引为2)        data.iloc[i,3] = getlnglat(data.iloc[i,1])[1] # 纬度    except:        pass    #print(i)data\n\n\n3 经纬度计算距离安装工具包\npip install geopy\n3.1 导入工具包\nfrom geopy.distance import geodesic\n3.2 读取数据\n# 读取数据data = pd.read_excel(&#x27;C:/Users/yyz/Desktop/python办公技巧/data/经纬度计算距离.xlsx&#x27;)data\n\n3.3 计算距离\n# 将经纬度赋值给变量,简化wd1 = data[&#x27;纬度1&#x27;].tolist()jd1 = data[&#x27;经度1&#x27;].tolist()wd2 = data[&#x27;纬度2&#x27;].tolist()jd2 = data[&#x27;经度2&#x27;].tolist()lis1 = []for i in range(len(data)):    j= geodesic((wd1[i],jd1[i]), (wd2[i],jd2[i])).km   # 纬度 经度  纬度 经度    lis1.append(j)    #print(i)data[&#x27;距离&#x27;] = lis1data\n4 百度经纬度转高德经纬度公司有2个系统,用的坐标系不一样, 有时候需要转换一下\n4.1 工具包\n# 导入工具包import mathimport pandas as pd\n4.2 定义函数\n# 定义转换函数def bdToGaoDe(lon,lat):    PI = 3.14159265358979324 * 3000.0 / 180.0    x = lon - 0.0065    y = lat - 0.006    z = math.sqrt(x * x + y * y) - 0.00002 * math.sin(y * PI)    theta = math.atan2(y, x) - 0.000003 * math.cos(x * PI)    lon = z * math.cos(theta)    lat = z * math.sin(theta)    return lon,lat\n4.3 单个转换\n# 单个转换bdToGaoDe(116.512885, 39.847469)(116.50647396357492, 39.84120409781157)\n4.4 批量转换\n# 读取数据data = pd.read_excel(&#x27;C:/Users/yyz/Desktop/python办公技巧/data/百度经纬度转高德.xlsx&#x27;)data.head()\n\nwd = data[&#x27;纬度&#x27;].tolist()jd = data[&#x27;经度&#x27;].tolist()# 定义一个空列表li1 = []for i in range(len(data)):    j  = bdToGaoDe(jd[i],wd[i])    li1.append(j)    li1data[&#x27;经度_re&#x27;] = [i[0] for i in li1]data[&#x27;纬度_re&#x27;] = [i[1] for i in li1]data.head()\n\n5 Excel文件批量合并5.1 工具包\n# 导入工具包import pandas as pdimport os\n5.2  获取文件列表\n# 设置文件路径path = &#x27;C:/Users/yyz/Desktop/python办公技巧/data/数据合并/&#x27;# 空列表, 用于存放文件路径files = []for file in os.listdir(path):    if file.endswith(&quot;.xlsx&quot;):        files.append(path+file)# 查看列表files\n5.3 转换存储数据\n# 定义一个空的dataframedata = pd.DataFrame()  # 遍历所有文件for file in files:    datai = pd.read_excel(file)    datai_len = len(datai)    data = data.append(datai)   # 添加到总的数据中    print(&#x27;读取%i行数据,合并后文件%i列, 名称：%s&#x27;%(datai_len,len(data.columns),file.split(&#x27;/&#x27;)[-1]))         # 查看是否全部读取，格式是否出错# 重置索引    data.reset_index(drop=True,inplace=True)\n\n6 Word文件批量转pdf只能转docx文件,转doc文件会报错, 工具包安装\npip install docx2pdf\n\n6.1 导入工具包\n# 安装工具包:#　导入工具包from docx2pdf import convertimport os\n6.2 单个转换\n# 单个转换convert(&quot;c:/users/yyz/desktop/魔方公式.docx&quot;, &quot;c:/users/yyz/desktop/excel笔记.pdf&quot;)\n6.3 批量转换\n# 文件位置path = &#x27;C:/Users/yyz/Desktop/python办公技巧/data/word转pdf/&#x27;# 定义空list,存放文件列表files = []for file in os.listdir(path):    if file.endswith(&quot;.docx&quot;):        files.append(path+file)filesfor file in files:   convert(file,file.split(&#x27;.&#x27;)[0]+&#x27;.pdf&#x27;)   print(file+&#x27;转换成功&#x27;)\n7 批量读取word中表格数据工具包安装\npip install python-docx\n\n7.1 导入工具包\nimport docx\n\n# 读取word文件doc = docx.Document(&#x27;C:/Users/yyz/Desktop/python办公技巧/data/word信息.docx&#x27;)# 获取文档中所有表格对象的列表biaoges = doc.tables \n\n7.2  不规范的表格\ncells = biaoges[1]._cellscells_lis = [[cell.text for cell in cells]]\n\nimport pandas as pdimport numpy as npdatai = pd.DataFrame(cells_lis)datai = datai[[1,3,7,9,14,16,19,21]]datai.columns = [&#x27;姓名&#x27;,&#x27;年龄&#x27;,&#x27;籍贯&#x27;,&#x27;住址&#x27;,&#x27;工作单位&#x27;,&#x27;电话&#x27;,&#x27;是否党员&#x27;,&#x27;出生日期&#x27;]datai\n\n7.3 规范数据\n# 获取第1个表格行丨rowi = len(biaoges[0].rows)rowi\n\n# 定义空列表lis1 = []# for循环获取第一个表的数据for i in range(1,rowi):  # 从第2行开始循环    lis1.append([biaoges[0].cell(i,0).text,                 biaoges[0].cell(i,1).text,                 biaoges[0].cell(i,2).text,                 biaoges[0].cell(i,3).text,                 biaoges[0].cell(i,4).text])\n\n# 创建一个dataframedata1 = pd.DataFrame(lis1,columns=[&#x27;日期&#x27;,&#x27;品类&#x27;,&#x27;数量&#x27;,&#x27;价格&#x27;,&#x27;金额&#x27;])data1\n\n7.4 批量读取\nimport pandas as pdimport osos.chdir(&#x27;C:/Users/yyz/Desktop/python办公技巧/data/word信息/&#x27;)\n\nlis1=[]for file in os.listdir(&#x27;.&#x27;):    if file.endswith(&#x27;.docx&#x27;):        doc = docx.Document(&#x27;./&#x27;+file)        biaoges = doc.tables        rowi = len(biaoges[0].rows)        for i in range(1,rowi):            lis1.append([biaoges[0].cell(i,0).text,                     biaoges[0].cell(i,1).text,                     biaoges[0].cell(i,2).text,                     biaoges[0].cell(i,3).text,                     biaoges[0].cell(i,4).text])\n\n# 创建dataframe            data1 = pd.DataFrame(lis1,columns=[&#x27;日期&#x27;,&#x27;品类&#x27;,&#x27;数量&#x27;,&#x27;价格&#x27;,&#x27;金额&#x27;])data1\n\n8 用outlook批量发邮件8.1 导入工具包\nimport win32com.client as win32import pandas as pd\n8.2 读取数据\n# 读取数据data1 = pd.read_excel(&#x27;C:/Users/yyz/Desktop/python批量发送邮件.xlsx&#x27;,sheet_name=&#x27;发送邮件&#x27;)data1.fillna(&#x27;&#x27;,inplace=True)\n8.3 发送邮件\n# 运行outlookoutlook = win32.Dispatch(&quot;outlook.Application&quot;)   # for循环发送文件for i in range(data1.shape[0]):       mail = outlook.CreateItem(0)   # 创建一个邮件对象  win32.constants.olMailItem    mail.To = data1.iloc[i,0]      #收件人    mail.CC = data1.iloc[i,1]      #抄送人    mail.Subject = data1.iloc[i,2]    #邮件主题    mail.HTMLBody = data1.iloc[i,3]           # 邮件正文 html格式   # mail.Body = data1.iloc[i,3]              # 邮件正文    mail.Attachments.Add(data1.iloc[i,4])     # 附件    mail.Send() #发送    i +=1print(&#x27;发送邮件%i份&#x27;%i)\npython办公自动化的技巧还有很多, python好掌握, 能帮助我们提升工作效率, 这也是很多非编程人员学习python的原因之一.\n"},{"title":"Python中的日期数据","url":"/2023/12/03/Python%E4%B8%AD%E7%9A%84%E6%97%A5%E6%9C%9F%E6%95%B0%E6%8D%AE/","content":"1 转换成日期格式使用pandas中read_excel()方法读取excel文件，并将数据转换成日期格式。\nimport pandas as pd # 导入pandas工具库，并简写为pd# import numpy as np# import datetimedf = pd.read_excel(&#x27;./日期问题.xlsx&#x27;) # 读取电脑上的excel文件，并取名为df（可自定义）#　将日期列转成日期格式df[&#x27;日期&#x27;] = pd.to_datetime(df[&#x27;日期&#x27;])   \n\n.默认为程序运行当前的路径或者我们指定好的一个路径。有时候还可能见到两个点的写法（..），表示当前路径的上一级。简化代码书写\n\ndt模块可轻松获取日期基本属性\n# 转年月日格式(字符串文本)df[&#x27;年月日&#x27;] = df[&#x27;日期&#x27;].apply(lambda x: x.strftime(&#x27;%Y%m%d&#x27;))df[&#x27;年&#x27;]=df[&#x27;日期&#x27;].dt.year  df[&#x27;季度&#x27;]=df[&#x27;日期&#x27;].dt.quarterdf[&#x27;月&#x27;]=df[&#x27;日期&#x27;].dt.monthdf[&#x27;日&#x27;]=df[&#x27;日期&#x27;].dt.day   df[&#x27;星期几&#x27;]=df[&#x27;日期&#x27;].dt.dayofweekdf[&#x27;周次&#x27;]=df[&#x27;日期&#x27;].dt.weekdf[&#x27;时&#x27;]=df[&#x27;日期&#x27;].dt.hourdf[&#x27;分&#x27;]=df[&#x27;日期&#x27;].dt.minutedf[&#x27;秒&#x27;]=df[&#x27;日期&#x27;].dt.second\n\n２计算一年中的第几天, 第几个10分钟, 日期转数值通过对天, 时,分的四则运算将日期转为序列数值数据\ndf[&#x27;一年中的第几天&#x27;]=df[&#x27;日期&#x27;].dt.dayofyeardf[&#x27;一天中的第几分钟&#x27;]=df[&#x27;日期&#x27;].apply(lambda x: x.minute + x.hour*60) df[&#x27;一天中的第几个10分钟&#x27;] = df[&#x27;时&#x27;] * 6 + df[&#x27;分&#x27;] // 10df[&#x27;数值&#x27;] = df[&quot;日期&quot;].values.astype(np.int64) // 10 ** 9# 转年月(数值)df[&#x27;年月&#x27;] = df[&#x27;日期&#x27;].dt.year * 100 + df[&#x27;日期&#x27;].dt.month  \n\n３判断日期是否闰年，年初年末，月初月末…apply() 和lambda()方法使用. python中2个强大的高阶函数. \ndf[&#x27;是否闰年&#x27;] = df[&#x27;日期&#x27;].apply(lambda x: x.is_leap_year) # 是否闰年df[&#x27;是否月初&#x27;] = df[&#x27;日期&#x27;].apply(lambda x: x.is_month_start) # 是否月初df[&#x27;是否月末&#x27;] = df[&#x27;日期&#x27;].apply(lambda x: x.is_month_end)   # 月末df[&#x27;是否季节初&#x27;] = df[&#x27;日期&#x27;].apply(lambda x: x.is_quarter_start)  # 季度初df[&#x27;是否季节末&#x27;] = df[&#x27;日期&#x27;].apply(lambda x: x.is_quarter_end) # 季度末df[&#x27;是否年初&#x27;] = df[&#x27;日期&#x27;].apply(lambda x: x.is_year_start)  # 年初df[&#x27;是否年尾&#x27;] = df[&#x27;日期&#x27;].apply(lambda x: x.is_year_end)  # 年内末df[&#x27;是否周末&#x27;] = df[&#x27;日期&#x27;].apply(lambda x: True if x.dayofweek in [5, 6] else False)  # 是否周末df.loc[((df[&#x27;时&#x27;] &gt;= 8) &amp; (df[&#x27;时&#x27;] &lt; 22)), &#x27;是否营业时间&#x27;] = True\n\n４字符串时段，季节构造字典, 用map方法进行替换. \nperiod_dict =&#123;    23: &#x27;深夜&#x27;, 0: &#x27;深夜&#x27;, 1: &#x27;深夜&#x27;,    2: &#x27;凌晨&#x27;, 3: &#x27;凌晨&#x27;, 4: &#x27;凌晨&#x27;,    5: &#x27;早晨&#x27;, 6: &#x27;早晨&#x27;, 7: &#x27;早晨&#x27;,    8: &#x27;上午&#x27;, 9: &#x27;上午&#x27;, 10: &#x27;上午&#x27;, 11: &#x27;上午&#x27;,    12: &#x27;中午&#x27;, 13: &#x27;中午&#x27;,    14: &#x27;下午&#x27;, 15: &#x27;下午&#x27;, 16: &#x27;下午&#x27;, 17: &#x27;下午&#x27;,    18: &#x27;傍晚&#x27;,    19: &#x27;晚上&#x27;, 20: &#x27;晚上&#x27;, 21: &#x27;晚上&#x27;, 22: &#x27;晚上&#x27;,&#125;df[&#x27;时间段&#x27;]=df[&#x27;时&#x27;].map(period_dict)# 一年中的哪个季度season_dict = &#123;    1: &#x27;春季&#x27;, 2: &#x27;春季&#x27;, 3: &#x27;春季&#x27;,    4: &#x27;夏季&#x27;, 5: &#x27;夏季&#x27;, 6: &#x27;夏季&#x27;,    7: &#x27;秋季&#x27;, 8: &#x27;秋季&#x27;, 9: &#x27;秋季&#x27;,    10: &#x27;冬季&#x27;, 11: &#x27;冬季&#x27;, 12: &#x27;冬季&#x27;,&#125;df[&#x27;季节&#x27;]=df[&#x27;月&#x27;].map(season_dict)\n\n５for循环快捷计算python中的getattr()方法\ntime_features = [&#x27;year&#x27;, &#x27;month&#x27;, &#x27;quarter&#x27;, &#x27;week&#x27;, &#x27;day&#x27;, &#x27;dayofweek&#x27;, &#x27;dayofyear&#x27;]dtype = np.int16for time_feature in time_features:    df[time_feature] = getattr(df[&#x27;日期&#x27;].dt, time_feature).astype(dtype)\n\n６时间间隔天数计算日期与一指定日期或者今天日期相比, 计算间隔天数\n# 设置初始的时间base_time = datetime.datetime.strptime(&#x27;2021-06-01&#x27;, &#x27;%Y-%m-%d&#x27;)# 计算时间差df[&#x27;时间差&#x27;] = df[&#x27;日期&#x27;].apply(lambda x: x-base_time).dt.days   # 距离今天天数 df[&#x27;间隔天数&#x27;] = list(map(lambda x: x.days, pd.to_datetime(&#x27;today&#x27;) - df[&#x27;日期&#x27;]))"},{"title":"pandas数据分析处理52个常用技巧","url":"/2023/12/03/pandas%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%A4%84%E7%90%8652%E4%B8%AA%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7/","content":"导入工具包# pandas 和numpy是两个基础的工具包import numpy as npimport pandas as pd# matplotlib seaborn是作图工具包import matplotlib.pyplot as pltimport seaborn as sns# 通过os设置默认路径import osos.chdir(&#x27;C:/Users/用户/Desktop/&#x27;)  # 桌面的路径# 图表中文显示问题plt.rcParams[&#x27;font.sans-serif&#x27;]=[&#x27;SimHei&#x27;] #用来正常显示中文标签plt.rcParams[&#x27;axes.unicode_minus&#x27;]=False #用来正常显示负号# 不显示预警import warnings  warnings.filterwarnings(&#x27;ignore&#x27;)\nspyder中快捷方式# 注释、取消注释Ctrl+1# 块注释 / 取消块注释  Ctrl+4/5# 从当前光标所在行开始执行F9\n读取excel文件# 读取文件df = pd.read_excel(&#x27;文件.xlsx&#x27;)#　读取文件同时筛选需要的列df = pd.read_excel(&#x27;文件.xlsx&#x27;)[[&#x27;&#x27;,&#x27;&#x27;]] # 读取并筛选几列# 读取特定的工作表df = pd.read_excel(&#x27;文件.xlsx&#x27;，sheet_name=&#x27;明细&#x27;) # 读取某个sheet表# with方法读取with pd.ExcelFile(&#x27;path_to_file.xls&#x27;) as xls:    df1 = pd.read_excel(xls, &#x27;Sheet1&#x27;)    df2 = pd.read_excel(xls, &#x27;Sheet2&#x27;)\n读取csv和txt文件# 分隔符: \\s 表示空白字符; \\s+多个空白字符; \\r回车; \\n换行; \\t水平制表符; \\v垂直制表符df = pd.read_csv(&#x27;文件.txt&#x27;,sep=&#x27;\\s+&#x27;,error_bad_lines=False)    \n批量读取同一文件夹下文件1for root, dirs, files in os.walk(&#x27;.&#x27;,topdown=False):    print(files)num = len(files)   # 获取文件个数data = pd.DataFrame()  # 定义一个空的dataframe# 遍历所有文件for i in range(num):    datai = pd.read_excel(&#x27;./%s&#x27; %files[i])       datai_len = len(datai)    data = data.append(datai)   # 添加到总的数据中    print(&#x27;文件%i列, 第%i个表,读取%i行数据,名称：%s&#x27;%(len(data.columns),i,datai_len,files[i]))     # 查看是否全部读取，格式是否出错    data.reset_index(drop=True,inplace=True)\n批量读取同一文件夹下的文件2# 导入工具包import pandas as pdimport numpy as npimport os# 路径path = &#x27;d:/文件路径/&#x27;# 文件列表files = []for file in os.listdir(path):    if file.endswith(&quot;.csv&quot;):        files.append(path+file)# 定义一个空的dataframedata = pd.DataFrame()  # 遍历所有文件for file in files:    datai = pd.read_csv(file,encoding=&#x27;gbk&#x27;)    datai_len = len(datai)    data = data.append(datai)   # 添加到总的数据中    print(&#x27;读取%i行数据,合并后文件%i列, 名称：%s&#x27;%(datai_len,len(data.columns),file.split(&#x27;/&#x27;)[-1]))         # 查看是否全部读取，格式是否出错# 重置索引    data.reset_index(drop=True,inplace=True)\n批量读取同一文件夹下的文件3# 循环读取数据n = 1for file in files:        with open(file, &#x27;r&#x27;,encoding=&#x27;gbk&#x27;) as f_input:        lisi= []        for line in f_input:            lisi.append(list(line.strip().split(&#x27;|&#x27;)))                datai = pd.DataFrame(lisi)    datai2 = guolv(datai)    data = data.append(datai2)                print(&#x27;读取第%i个文件,件名%s,文件%i行,文%i列.处理后文件%i行,%i列&#x27; %(n,file,datai.shape[0],datai.shape[1],datai2.shape[0],datai2.shape[1]))    n = n + 1\n数据导出为excel，同一工作簿with pd.ExcelWriter(&#x27;文件.xlsx&#x27;) as writer:    df1.to_excel(writer, sheet_name=&#x27;文件1&#x27;)    df2.to_excel(writer, sheet_name=&#x27;文件2&#x27;)\n数据导出为excel，分组导出到同一工作簿writer = pd.ExcelWriter(&#x27;文件.xlsx&#x27;)for name , group in df.groupby(&#x27;名称&#x27;):    group.to_excel(writer,sheet_name=name,index=False)\n数据导出为excel，分组导出到不同的工作簿for name , group in df.groupby(&#x27;名称&#x27;):    group.to_excel(name+&#x27;.xlsx&#x27;,index=False)\n获取当前时间import timetim = time.strftime(&quot;%Y-%m-%d%H%M%S&quot;, time.localtime()) \n保存图片分辨率设置plt.savefig(&#x27;名称.png&#x27;,dpi=150)  \n数据查看df.describe()   # 描述统计df.info()    # 基本信息df.dtypes    #　列格式类型df.head(2)    ＃前n行df.tail(2)    #后ｎ行df.shape    ＃维度df.index  #索引df.columns  ＃列名df.sample(10)   #随机抽样df.resample()　 #随机抽样\n行列处理（删除、排序）# 删除列del df[&#x27;变量名&#x27;]df.drop(&#x27;变量名&#x27;,axis=1,inplace=True)# 删除行df.drop(&#x27;c&#x27;)# 更改列名df.columns= [&#x27;var1&#x27;,&#x27;var2&#x27;,&#x27;var3&#x27;]  # 列名的个数 = 字段个数df.rename(columns = &#123;&#x27;名称前&#x27;:&#x27;名称后&#x27;&#125;,inplace=True)   # columns 不能少# series中改列名s.rename(&#x27;名称&#x27;,inplace=True)# 调整列的顺序df1 = df1[[&#x27;var1&#x27;,&#x27;var2&#x27;,&#x27;var3&#x27;]]# 调整行的顺序df2 = df1.reindex([&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;d&#x27;,&#x27;e&#x27;]) # 返回一个新的DataFrame，按新的索引进行排序\n缺失值（查看、替换、计数）# 判断是否是缺失值df.isnull()  #不能省略括号df.notnull()# 计算缺失值个数s.isnull().value_counts()# 每列缺失值个数df.isna().sum()  # 缺失值个数# 填充缺失值df[&#x27;A&#x27;].fillna(&#x27;缺失数据&#x27;,inplace=True)  data1.fillna(method=&#x27;pad&#x27;)   # 类似于excel中用上一个单元格内容批量填充  # 删除指定列包含缺失值的行data.dropna(subset=[&quot;C&quot;],inplace=True)    # []不能少data.dropna(how=&quot;all&quot;)   # 删除全为空的行data.dropna(thresh=2)    #删除有效数据小于2的数据# 缺失值个数并排序df.isnull().sum().sort_values(ascending=False).head()\n重复值（查看、删除）# 不重复项df[&#x27;A&#x27;].unique()  df[&#x27;A&#x27;].nunique() #查看不重复值个数df[&#x27;A&#x27;].unique().tolist()   # 转list df[&#x27;A&#x27;].value_counts()  # 计数# 去重set(data2[&#x27;名称&#x27;])# 查看重复项，返回True Falsedf.duplicated()  # 查看重复的数据data4 = data3[data3.duplicated(subset=&#x27;var1&#x27;,keep=False)]  # 删除重复项df.drop_duplicates([&#x27;var&#x27;],inplace=True)# 按两列去重data.drop_duplicates(subset=[&#x27;A&#x27;,&#x27;B&#x27;],keep=&#x27;first&#x27;,inplace=True)  # 分组计算不重复项个数result = df.groupby([&#x27;var1&#x27;,&#x27;var2&#x27;]).agg(&#123;&#x27;var3&#x27;:&#x27;nunique&#x27;,&#x27;var4&#x27;:[&#x27;min&#x27;,&#x27;max&#x27;]&#125;)\n修改格式((格式转换, 百分比, 格式判断))# 改变列的格式（文本型数值改成数值型数值）df[&#x27;var1&#x27;] = df[&#x27;var1&#x27;].astype(&#x27;int&#x27;)  # errors = &#x27;ignore&#x27;df[&#x27;var1&#x27;] = df[&#x27;var1&#x27;].astype(np.float)# 多列转换df[[&#x27;user_id&#x27;,&#x27;merchant_id&#x27;,&#x27;coupon_id&#x27;]]=df[[&#x27;user_id&#x27;,&#x27;merchant_id&#x27;,&#x27;coupon_id&#x27;]].astype(str)  df.infer_objects()  # 根据数据特征自动转换# 百分比格式data[&#x27;B_per%&#x27;] = data[&#x27;B_per&#x27;].apply(lambda x: &#x27;%.2f%%&#x27; % (x*100))# 判断格式，是否为字符串data[&#x27;var&#x27;].apply(lambda x:isinstance(x,str))\n普通筛选# loc筛选：选择符合条件的行df.loc[df[&quot;grade&quot;] == &quot;B&quot;].head()# 选择符合条件的行和特定的列df.loc[df[&quot;grade&quot;] == &quot;B&quot;, [&quot;member_id&quot;, &quot;grade&quot;]].head()# 选择符合条件的行和特定的列,并排序df.loc[df[&quot;grade&quot;] == &quot;B&quot;, [&quot;loan_amnt&quot;, &quot;grade&quot;]].sort([&quot;loan_amnt&quot;])# 多条件筛选df.loc[[(df[&quot;gradd&quot;]==&quot;B&quot;) &amp; (df[&quot;loan_amnt&quot;]&gt;5000), [&quot;member_id&quot;, &quot;term&quot; ]].head()# 反选data[~((data.发布时间.isnull()) &amp; (data.实际首试日期 &lt; &#x27;2018-11-1&#x27;))]# 反转行df.iloc[::-1, :] \n逻辑判断后筛选# isin筛选df[&quot;A&quot;].isin([1,2,3])#　多条件df[(df.AAA &lt;= 6) &amp; (df.index.isin([0, 2, 4]))]# loc和isin组合　df.loc[df[&#x27;sepal_length&#x27;].isin([5.8,5.1])]# 字符串isindf.loc[df[&#x27;grade&#x27;].isin([&#x27;北京&#x27;,&#x27;上海&#x27;])]#　字符串开头df[df[&#x27;A&#x27;].str.startswith(&#x27;北京&#x27;)]# contains筛选df[df[&#x27;商品名称&#x27;].str.contains(&quot;四件套&quot;)]# 多个筛选df_re =df[df[&#x27;公司&#x27;].str.contains(&#x27;公司A||公司B&#x27;)]# 筛选含特殊字符的df[df[&#x27;产业线&#x27;].str.contains(&#x27;\\?&#x27;)] # 多条件筛选data[(data[&#x27;var1&#x27;].str[0] == &#x27;M&#x27;)&amp;(data[&#x27;var2&#x27;].apply(lambda x : str(x)[0] == &#x27;8&#x27;))]# 索引特殊用法df[[i.endswith(&#x27;A&#x27;) for i in df.index]] # 按字符串长度筛选data = df[df[&#x27;名称&#x27;].str.len()&gt;5]# 按字符串开头筛选df[df[&#x27;名称&#x27;].str[0] == &#x27;M&#x27;]# 筛选列data = data.loc[:,~(data.columns.str.contains(&#x27;集团&#x27;))]# 筛选前几个最大值data = df.iloc[df[&#x27;名称&#x27;].nlargest(3).index]# 筛选由汉字开头的数据df = df[df[&#x27;名称&#x27;].str.contains(r&#x27;^[\\u4e00-\\u9fa5]&#x27;)]# 日期不是索引时, 按日期筛选 data[data[&#x27;时间&#x27;].apply(lambda x: x.year == 2019)]  data[data[&#x27;时间&#x27;].apply(lambda x: x.strftime(&#x27;%Y%m&#x27;)==&#x27;202008&#x27;)]\n分组后筛选# 分组后筛选前2个df2 = df1.groupby([&#x27;class&#x27;]).head(2)# 分组后筛选第2条或者倒数第2条数据df1.groupby(&#x27;class&#x27;).apply(lambda i:i.iloc[1] if len(i)&gt;1 else np.nan)df1.groupby(&#x27;class&#x27;).apply(lambda i:i.iloc[-2] if len(i)&gt;1 else np.nan)# 分组后按条件筛选data.groupby(&#x27;var1&#x27;).filter(lambda x: len(x[x[&#x27;var2&#x27;]==&#x27;A&#x27;])&gt;=1)data.groupby(&#x27;公司编码&#x27;).filter(lambda x:len(x)!=3)# groupby筛选方法1（先分组，然后筛选另一个变量中最小值）df.loc[df.groupby(&#x27;AA&#x27;)[&#x27;BB&#x27;].inxmin()]#groupby筛选方法2：（先排序，分组，然后筛选每一组中的第一个）df.sort_values(by=&#x27;BB&#x27;).groupby(&#x27;AA&#x27;,as_index=False).first()# groupby筛选方法3：groupby与apply结合df.groupby(&#x27;aa&#x27;).apply(lambda x :  x[&#x27;BB&#x27;][x[&#x27;cc&#x27;].idxmax()]# 分组并排序df[[&#x27;A&#x27;,&#x27;B&#x27;]].groupby(&#x27;A&#x27;).mean().sort_values(&#x27;B&#x27;,ascending=False).head()\n替换# 单个替换df[&#x27;判断&#x27;].replace([&#x27;B&#x27;,&#x27;C&#x27;],np.nan,inplace=True)   #支持正则表达式# 多个替换data[&#x27;var&#x27;].replace([&#x27;A&#x27;,&#x27;B&#x27;],[&#x27;a&#x27;,&#x27;b&#x27;],inplace=True)# loc原地替换df1.loc[df[&#x27;sex&#x27;]==&#x27;female&#x27;, &#x27;sex&#x27;] = 1df1.loc[df[&#x27;sex&#x27;]==&#x27;male&#x27;, &#x27;sex&#x27;] = 0# 字典df.replace(&#123;&#x27;female&#x27;:1, &#x27;male&#x27;:0&#125;)# 适合二分法df1[&#x27;sex&#x27;] = df1[&#x27;sex&#x27;].map(lambda x:1 if x==&#x27;female&#x27; else 0)# applydf_zb[&#x27;var&#x27;] = df_zb[&#x27;var&#x27;].apply(lambda x: x[:-1] if x[-1].isalpha() else x)data3[&#x27;var&#x27;] = data3[&#x27;var&#x27;].apply(lambda x: x[:-1] if x[-1] == &#x27;s&#x27; else x)# np.wheredata[&#x27;var&#x27;] = np.where(data[&#x27;var&#x27;] == &#x27; &#x27;,0,data[&#x27;var&#x27;])\n字符串处理print(&#x27;我的名字是%s，今年%i岁，体重%.2f&#x27;%(&#x27;小明&#x27;,20,70.1))# 去除空格，改变大小写df[&#x27;term&#x27;] = df[&#x27;term&#x27;].map(str.strip)  #去除左右两边的空格，strip后面是否带括号df[&#x27;term&#x27;] = df[&#x27;term&#x27;].str.strip()df[&#x27;term&#x27;] = df[&#x27;term&#x27;].map(str.lstrip)  #去除左边的空格df[&#x27;term&#x27;] = df[&#x27;term&#x27;].map(str.rstrip)  #去除右边的空格df[&#x27;term&#x27;] = df[&#x27;term&#x27;].map(str.upper)  # 改成全部大写df[&#x27;term&#x27;] = df[&#x27;term&#x27;].map(str.lower) # 改成全部小写df[&#x27;term&#x27;] = df[&#x27;term&#x27;].map(str.title) # 改成首字母大写# 去掉所有空格data = data.applymap(lambda x: x.strip() if isinstance(x,str) else x)\n字符串判断# 判断是否为某一特定格式df[&#x27;emp_length&#x27;].apply(lambda x: x.isalpha())   #是否为字母df[&#x27;emp_length&#x27;].apply(lambda x: x. isalnum ())  #是否全未数字或者字母df[&#x27;emp_length&#x27;].apply(lambda x: x. isdigit ())  #是否为数字\n字符串拆分s.str.split(&#x27;_&#x27;)  # 拆分，结果是列表s.str.split(&#x27;_&#x27;).str.get(1)   # 拆分后取第一个，可用于生成新变量s.str.split(&#x27;_&#x27;).str[1]       # 拆分后取第一个，可用于生成新变量s.str.split(&#x27;_&#x27;, expand=True) # 拆分，并展开成多列s.str.split(&#x27;_&#x27;, expand=True, n=1)   # 按第一个拆分s.str.rsplit(&#x27;_&#x27;, expand=True, n=1)  # 按最后一个拆分data[&#x27;var&#x27;] = data[&#x27;var&#x27;].str.split(&#x27;?&#x27;,expand=True)[0]\n索引# 把列变成索引df.set_index(&#x27;时间&#x27;,inplace=True, drop = False)  df.set_index([&#x27;r&#x27;,&#x27;s&#x27;], inplace = True) # r为一级，s为二级# 取消层次化索引，将索引变回列df.reset_index(inplace=True)df.reset_index(drop=True,inplace=True,level = None)# 按索引排序df.sort_index(inplace=True,ascending=False)# 更新索引（行、列都可以修改）df2 = df1.reindex([&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;d&#x27;,&#x27;e&#x27;]) # 返回一个新的DataFrame，按新的索引进行排序df2 = df1.reindex([&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;d&#x27;,&#x27;e&#x27;],  fill_value=0) # 多级索引问题（索引可以在行，也可以在列）df.index.names=[&#x27;类型&#x27;,&#x27;供应商&#x27;]  # 取名称df.columns.names=[&#x27;类型&#x27;,&#x27;日期&#x27;]  # 取名称df1 = df.swaplevel(&#x27;类型&#x27;,&#x27;日期&#x27;,axis=1)  #调整多级索引次序df1 = df.sort_index(level=0, axis=1, ascending=True,sort_remaining=False)   # sort_remaining 默认是Truedf1 = df.sum(axis=1,level=&#x27;类型&#x27;)  # 通过索引对多列进行求和\n排序# na_position对NaN值的处理方式，可以选择first和last两种方式df.sort()   # 单列排序df.sort([&quot;loan_amnt&quot;],ascending=False)  # 降序# 多列进行排序,加入一个列表df.sort([&quot;loan_amnt&quot;,&quot;int_rate&quot;],ascending=False)# 升序排列后选择前10df.sort([&quot;loan_amnt&quot;],ascending=True).head(10)# 自定义排序df.sort_values(by=[&#x27;日期&#x27;,&#x27;类型&#x27;,&#x27;距离&#x27;],ascending=True,inplace=True,na_position = &#x27;last&#x27;)   # 索引排序df.sort_index(inplace=True)\n日期# 设置成日期格式df[&#x27;创建日期&#x27;] = pd.to_datetime(data_final[&#x27;创建日期&#x27;],format=&#x27;%Y/%m/%d&#x27;)# 设置为日期索引df.set_index(&#x27;订单提交时间&#x27;,inplace=True)# 日期索引排序df.sort_index(inplace=True,ascending=False)# 日期索引的筛选df_2019 = df[&#x27;2019&#x27;]  # 日期索引可以直接这样筛选  df[&#x27;2019-01&#x27;]  #按月筛选df[&#x27;2019-03-12&#x27;:&#x27;2019-03-12&#x27;] #筛选某一天数据# 改变显示频率（只针对日期索引）df = df.to_period(&#x27;M&#x27;)  # 针对索引，关键步骤  Q 季度 Y年 D天# 计算时间间隔data[&#x27;间隔天数&#x27;] = list(map(lambda x: x.days, pd.to_datetime(&#x27;today&#x27;) - data[&#x27;生产时间&#x27;]))df[&#x27;天数&#x27;] = df[&#x27;天数&#x27;].apply(lambda x: x.days)# 单独表示间隔天数from datetime import timedeltaaDay = timedelta(days=1)# 时间对象格式化df[&#x27;DATE&#x27;] = [datetime.strftime(x,&#x27;%Y-%m-%d&#x27;) for x in df[&#x27;DATE&#x27;]]# 时间分组后计算final = data.groupby(data[&#x27;订单时间&#x27;].apply(lambda x: x.strftime(&#x27;%Y%m&#x27;)))[&#x27;总价&#x27;].sum()/10000data.groupby(data[&#x27;日期&#x27;].apply(lambda x: datetime.strftime(x,&#x27;%Y-%m-%d&#x27;)))[&#x27;var&#x27;].count()data.set_index(&#x27;日期&#x27;).groupby(&#x27;供应商&#x27;)[&#x27;数量&#x27;].rolling(&#x27;7D&#x27;).sum().reset_index()final1 = data.groupby([data.to_period(&#x27;Q&#x27;).index,&#x27;var&#x27;]).apply(lambda g: np.average(g[&#x27;var2&#x27;], weights=g[&#x27;模次&#x27;])).reset_index()# 当前时间import timestarttime = time.time()# 当前日期tim = time.strftime(&quot;%Y-%m-%d%H%M%S&quot;, time.localtime())# pd.date_range  时间戳  pd.period_range 时间周期  pd.timedelta_range  时间间隔datelist = pd.date_range(&#x27;2020/11/21&#x27;, periods=5)datelist = pd.date_range(&#x27;2020/11/21&#x27;, periods=5,freq=&#x27;M&#x27;)# 生成的数据是每月月初index= pd.date_range(&#x27;2019/02/01&#x27;, periods=23,freq=&#x27;MS&#x27;)pd.date_range(&#x27;2017-01-01 01:00:00&#x27;, &#x27;2017-01-01 02:00:00&#x27;, freq= &#x27;5min&#x27;)# 当前日期前3天import pandas as pdfrom datetime import datetimeimport timelis = pd.date_range(end=&#x27;2021-4-21&#x27;,periods=3)str_lis = [datetime.strftime(x,&#x27;%Y-%m-%d&#x27;) for x in lis]lis = pd.date_range(end=time.strftime(&quot;%Y/%m/%d&quot;),periods=3)str_lis = [datetime.strftime(x,&#x27;%Y-%m-%d&#x27;) for x in lis]\n判断是否为假期import datetimeimport chinese_calendardemo_time = datetime.date(2018, 10, 2)# 判断是否是节假日data_is_holiday = chinese_calendar.is_holiday(demo_time)  # True# 判断某日是否工作日data_is_workday = chinese_calendar.is_workday(demo_time)  # False\n数据分组# 方法1data[&#x27;for_m&#x27;] = pd.cut(data[&#x27;fortune_x&#x27;],[0,50,70,500],labels = [&#x27;财低&#x27;,&#x27;财中&#x27;,&#x27;财高&#x27;])# 方法2df = pd.DataFrame(&#123;&#x27;value&#x27;: np.random.randint(0, 100, 20)&#125;)labels = [&quot;&#123;0&#125; - &#123;1&#125;&quot;.format(i, i + 9) for i in range(0, 100, 10)]df[&#x27;group&#x27;] = pd.cut(df.value, range(0, 105, 10), right=False, labels=labels)\n多表合并# 默认纵向连接，产生新的坐标轴   df = pd.concat([df1,df2],ignore_index=True)  # merge 合并pd.merge(left,  right,  left_on=&quot;lkey&quot;,  right_on=&quot;rkey&quot;,suffixes=(&quot;_left&quot;,  &quot;_right&quot;))pd.merge(df, df, left_on=[&#x27;&#x27;,&#x27;&#x27;,&#x27;&#x27;], right_on=[&#x27;&#x27;,&#x27;&#x27;,&#x27;&#x27;], suffixes=(&#x27;&#x27;,&#x27;&#x27;))# append 表头一致的多张表，进行连接（上下连接）df1.append(df2).append(df3)# combine_first数据填补.有两张表left和right，一般要求它们的表格结构一致，数据量也一致，使用right的数据去填补left的数据缺漏, 如果在同一位置left与right数据不一致，保留left的数据df1.combine_first(df2)\n常用函数count()非空观测数量  sum()所有值之和      mean()所有值的平均值   median()所有值的中位数mode()值的模值       std()值的标准偏差    var()方差             min()所有值中的最小值  max()所有值中的最大值 abs()绝对值          prod()数组元素的乘积  cumsum()累计总和     cumprod()累计乘积     skew()偏斜          kurt()峰度           quantile()分位数apply()通用申请       cov()协方差         corr() 相关系数\n描述性统计df.describe(include=[&#x27;object&#x27;])    #object - 汇总字符串列  number - 汇总数字列 all - 将所有列汇总在一起(不应将其作为列表值传递)df.describe().round(2)   # 只保留两位小数df.describe().round(2).T   #只保留两位小数并转置df.groupby(&#x27;性别&#x27;).describe().unstack()df.groupby(&#x27;性别&#x27;)[&#x27;身高&#x27;].describe().unstack()df.round(3)  # 数据可以取消科学计数法？df = df.round(0)   # 都改为整数# 保留2位小数df[&#x27;a&#x27;]=df[&#x27;mean&#x27;].round(decimals=2) df[&#x27;b&#x27;]=df[&#x27;mean&#x27;].map(lambda x:(&quot;%.2f&quot;)%x) df[&#x27;c&#x27;]=df[&#x27;mean&#x27;].map(lambda x:format(x,&quot;.2%&quot;))description = [data.min(), data.max(), data.mean(), data.std()]  # 依次计算最小值、最大值、均值、标准差description = pd.DataFrame(description, index = [&#x27;Min&#x27;, &#x27;Max&#x27;, &#x27;Mean&#x27;, &#x27;STD&#x27;]).T  # 将结果存入数据框print(&#x27;描述性统计结果：\\n&#x27;,np.round(description, 2))\n数据预览# 在cmd中安装pip install pandas-profiling   import  pandas_profilingpro = pandas_profiling.ProfileReport(data1)pro.to_file(&#x27;output_file.html&#x27;)\n显示百分比# 元素变化百分比 每个元素与其前一个元素进行比较，并计算变化百分比df.pct_change() \n协方差# 协方差，cov用来计算序列对象之间的协方差s1.cov(s2)df[&#x27;a&#x27;].cov(df[&#x27;b&#x27;])\n相关性# 相关性，pearson(默认)，spearman和kendall之间的相关性df[&#x27;a&#x27;].corr(df[&#x27;b&#x27;]，method =&#x27;spearman&#x27;)print (frame.corr())\n排名s.rank() 或者 df.rank()  # （axis=0）或列（axis=1）  #  ascending=True 正向排名或者反向排名#  method （average ：并列组平均排名，min ：组中最低排名，max ：组中最高等级，first ：按在数组中出现的顺序分配等级）\n分组计算# 多组运算df.groupby([&#x27;班级&#x27;,&#x27;性别&#x27;])[&#x27;身高&#x27;].agg([np.sum,np.mean,np.std])df.groupby([&#x27;班级&#x27;,&#x27;性别&#x27;]).agg(&#123;&#x27;身高&#x27;:[&#x27;min&#x27;],&#x27;体重&#x27;:[&#x27;max&#x27;]&#125;)df.groupby(&#x27;flee&#x27;).agg(&#123;&#x27;身高&#x27;: [np.median, np.mean], &#x27;signs&#x27;: np.mean&#125;)df.agg(&#123;&#x27;A&#x27;:np.sum,&#x27;B&#x27;:np.mean&#125;)  # 对不同列进行不同的计算df[[&#x27;A&#x27;,&#x27;B&#x27;]].agg([np.sum,np.mean,np.min])  # 对多个变量进行多种计算# 时间分组 ，先用pd.to_datetime(字段,格式)将某一列转成日期格式df.groupby(df[&#x27;生日&#x27;].apply(lambda x:x.year)).count()# 分组后选第一个,一般数据先排序df.groupby(df[&#x27;生日&#x27;].apply(lambda x:x.year),as_index=False).first()       # Tail(n=1) head()# 找到每组中只有一个数据的df.groupby(df[&#x27;生日&#x27;].apply(lambda x:x.month),as_index=False).filter(lambda x: len(x)==1)data2.groupby(&#x27;var&#x27;).filter(lambda x:len(x)&gt;=10)data.groupby(data.index.year)[&#x27;年龄&#x27;].mean()# 加权平均final3_1 = data_jiep.groupby([&#x27;产业线&#x27;,&#x27;模号&#x27;]).apply(lambda g: np.average(g[&#x27;平均节拍&#x27;], weights=g[&#x27;模次&#x27;])).reset_index()# groupby作图data.groupby(&#x27;race&#x27;)[&#x27;flee&#x27;].value_counts().unstack().plot(kind=&#x27;bar&#x27;, figsize=(20, 4))data.groupby(&#x27;flee&#x27;)[&#x27;age&#x27;].plot(kind=&#x27;kde&#x27;, legend=True, figsize=(20, 5))# groupby中的几个函数# 累计  df.groupby(&#x27;key&#x27;).aggregate(&#x27;min&#x27;, np.median, max)# 过滤   df.groupby(&#x27;key&#x27;).filter(某个函数)# 转换    df.groupby(&#x27;key&#x27;).transform(lambda x: x- x.mean())#通过某一个字段分组后，选另一个字段的最小值，构成的数据df = pd.DataFrame(&#123;&#x27;AAA&#x27;: [1, 1, 1, 2, 2, 2, 3, 3],&#x27;BBB&#x27;: [2, 1, 3, 4, 5, 1, 2, 3]&#125;)df.loc[df.groupby(&quot;AAA&quot;)[&quot;BBB&quot;].idxmin()]# 按照一个字段排序，另一个字段分组，选取第一个df.sort_values(by=&quot;BBB&quot;).groupby(&quot;AAA&quot;, as_index=False).first()  #重新设置索引# transform后数据大小不变df[&quot;Order_Total&quot;] = df.groupby(&#x27;order&#x27;)[&quot;ext price&quot;].transform(&#x27;sum&#x27;)result0 = data1.to_period(&#x27;Q&#x27;).groupby(level=0).apply(lambda x :len(x[&#x27;var&#x27;].unique().tolist()))\n交叉表result1 = pd.crosstab(data.index,data[&#x27;产业线&#x27;],margins=True)\n数据透视表df.pivot_table(&#x27;价格&#x27;,index=&#x27;产地&#x27;,columns=&#x27;类别&#x27;,aggfunc=&#x27;max&#x27;,margins=True,fill_value=0,margins_name=&#x27;合计&#x27;)# 用字典形式，可不用values参数df.pivot_table(index=&#x27;sex&#x27;, columns=&#x27;class&#x27;, aggfunc=&#123;&#x27;surviced&#x27;:&#x27;sum&#x27;, &#x27;fare&#x27;:&#x27;mean&#x27;&#125;)result  = data.pivot_table(index=data3.to_period(&#x27;M&#x27;).index,columns= &#x27;是否异常&#x27;,values=&#x27;模号&#x27;, aggfunc=&#x27;count&#x27;)result1 = data.pivot_table(index= &#x27;var1&#x27;,columns=data[&#x27;var3&#x27;].apply(lambda x: x.strftime(&#x27;%Y&#x27;)),                      aggfunc=&#x27;count&#x27;,values=&#x27;var2&#x27;)\n窗口函数#索引需要为日期 对于明细数据，计算固定大小区域的指标s = pd.Series(np.random.randn(1000),index=pd.date_range(&#x27;1/1/2000&#x27;, periods=1000))s = s.cumsum()r = s.rolling(window=60)   # window：移动窗口的大小# min_periods：需要的非空数据点的阈值（否则结果为NA）# center：布尔值，是否将标签设置在中间（默认为False）df[&#x27;数量_re&#x27;] = df[&#x27;数量&#x27;].rolling(&#x27;7D&#x27;).sum()data1 = data.set_index(&#x27;入库日期&#x27;).groupby(&#x27;供应商&#x27;)[&#x27;入库量&#x27;].rolling(&#x27;7D&#x27;).sum().reset_index()\n标准化# 当越小越好时df[&#x27;var_nor&#x27;] = (df[&#x27;var&#x27;].max() - df[&#x27;var&#x27;]) / (df[&#x27;var&#x27;].max() - df[&#x27;var&#x27;].min())# 当越大越好时df[&#x27;var_nor&#x27;] = (df[&#x27;var&#x27;] - df[&#x27;var&#x27;].min()) / (df[&#x27;var&#x27;].max() - df[&#x27;var&#x27;].min())# 当中值为好是df[&#x27;var&#x27;] = np.abs(df[&#x27;var&#x27;]-标准值)df[&#x27;var_nor&#x27;] = (df[&#x27;var&#x27;].max() - df[&#x27;var&#x27;]) / (df[&#x27;var&#x27;].max() - df[&#x27;var&#x27;].min())# 可以写成通用函数def f2(data,col):    col_name = col + &#x27;_nor&#x27;    data_gp = data.groupby(&#x27;类别&#x27;).mean()    data_gp[col_name] = (data_gp[col] - data_gp[col].min() ) / (data_gp[col].max() - data_gp[col].min() )    return data_gp\n去除异常值def f2(data,col):    q1 = data[col].quantile(q=0.25)         q3 = data[col].quantile(q=0.75)    iqr = q3 - q1    t1 = q1 - 3*iqr    t2 = q3 + 3*iqr    return data[(data[col]&gt;t1)&amp;(data[col]&lt;t2)][[&#x27;类别&#x27;,col]]\n正态分布data_norm = pd.DataFrame(&#123;&#x27;正太分布&#x27;:np.random.normal(loc=60,scale=15,size=10000)&#125;)data_exp = pd.DataFrame(&#123;&#x27;指数分布&#x27;:np.random.exponential(scale=15,size=10000)+45&#125;)\n随机选择df[&#x27;strategy&#x27;] = np.random.choice([1,2,3],99)\n行列求和# 增加列合计df[&#x27;合计&#x27;]  = df.sum(axis=1)# 增加行合计df.loc[&#x27;合计&#x27;]  = df.sum(axis=0)\n数据平移data[&#x27;经度_前1天&#x27;] = data.groupby(&#x27;var&#x27;)[&#x27;经度&#x27;].shift(1)\n宽窄表转换test = pd.DataFrame(fake_data, columns=[&#x27;subject&#x27;, &#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;])test    subject    A    B    C0    math      88   70   601    english   90   80   78# 转换为窄表pd.melt(test, id_vars=[&#x27;subject&#x27;])data3 = pd.melt(data2, id_vars=[&#x27;var1&#x27;,&#x27;var2&#x27;])     subject    variable    value0    math       A           881    english    A           902    math       B           703    english    B           804    math       C           605    english    C           78\n转二维表df.to_numpy()\n字典转列表df.set_index(&#x27;ID&#x27;).T.to_dict(&#x27;list&#x27;)&#123;&#x27;p&#x27;: [1, 3, 2], &#x27;q&#x27;: [4, 3, 2], &#x27;r&#x27;: [4, 0, 9]&#125;\n转字典列表datajs = data.to_json(orient=&#x27;records&#x27;,force_ascii=False)# 名称，经度，维度，数值[&#123;&quot;name&quot;:&quot;虹桥火车站&quot;,&quot;lng&quot;:121.327908,&quot;lat&quot;:31.20033,&quot;value&quot;:3.5225437574&#125;,&#123;&quot;name&quot;:&quot;上海火车站&quot;,&quot;lng&quot;:121.46396,&quot;lat&quot;:31.255155,&quot;value&quot;:7.0937954904&#125;]\n两列中的较大值df[&#x27;z&#x27;]=df[[&#x27;x&#x27;,&#x27;y&#x27;]].max(axis=1)"},{"title":"pyechart生成地图","url":"/2023/12/03/pyechart%E7%94%9F%E6%88%90%E5%9C%B0%E5%9B%BE/","content":"代码\nfrom pyecharts import options as optsfrom pyecharts.charts import Geofrom pyecharts.globals import ChartType, SymbolTypec = (    Geo()    .add_schema(        maptype=&quot;china&quot;,        itemstyle_opts=opts.ItemStyleOpts(color=&quot;#323c48&quot;, border_color=&quot;#111&quot;),    )    .add(        &quot;&quot;,        [(&quot;广州&quot;, 55), (&quot;北京&quot;, 66), (&quot;杭州&quot;, 77), (&quot;重庆&quot;, 88)],        type_=ChartType.EFFECT_SCATTER,        color=&quot;white&quot;,    )    .add(        &quot;geo&quot;,        [(&quot;广州&quot;, &quot;上海&quot;), (&quot;广州&quot;, &quot;北京&quot;), (&quot;广州&quot;, &quot;杭州&quot;), (&quot;广州&quot;, &quot;重庆&quot;)],        type_=ChartType.LINES,        effect_opts=opts.EffectOpts(            symbol=SymbolType.ARROW, symbol_size=6, color=&quot;blue&quot;        ),        linestyle_opts=opts.LineStyleOpts(curve=0.2),    )    .set_series_opts(label_opts=opts.LabelOpts(is_show=False))    .set_global_opts(title_opts=opts.TitleOpts(title=&quot;Geo-Lines-background&quot;))    .render(&quot;geo_lines_background.html&quot;))\n\n&lt;iframe src=&quot;C:/Users/Administrator/Desktop/pyechart图/geo_lines_background.html&quot; width=&quot;800&quot; height=&quot;600&quot;&gt;&lt;/iframe&gt;\n\n"},{"title":"python计算昨天及以昨天为起点上月月末的两个日期","url":"/2023/12/03/python%E8%AE%A1%E7%AE%97%E6%98%A8%E5%A4%A9%E5%8F%8A%E4%BB%A5%E6%98%A8%E5%A4%A9%E4%B8%BA%E8%B5%B7%E7%82%B9%E4%B8%8A%E6%9C%88%E6%9C%88%E6%9C%AB%E7%9A%84%E4%B8%A4%E4%B8%AA%E6%97%A5%E6%9C%9F/","content":"\n工作中经常对两个日期的数据进行比较，比如一张报表是用昨天的数据和上月月末的数据进行比较，用python如何获取两个日期呢？\n\npython时间数据基础from datetime import date,timedelta,datetimeimport timedate.today() # 当天日期，年月日date.today()+timedelta(1) # 明天date(2011,10,1)date.today().strftime(&#x27;%Y-%m-%d&#x27;) # 转换成字符串date.today().year # 年date.today().month # 月date.today().day # 日datetime.now()  # 现在时间，年月日时分秒datetime.now()+timedelta(-1) # 昨天datetime(2011,10,1)datetime.now().strftime(&#x27;%Y-%m-%d&#x27;) # 转换成字符串datetime.now().year # 年datetime.now().month #月datetime.now().day # 日datetime.now().hour # 时datetime.now().minute # 分datetime.now().second # 秒time.time() # 当前时间的时间戳，一般计算两个时间间隔多少秒\n获取两个日期# 获取日期: 昨天日期, 以及以昨天日期为起点上月末的日期def riqi():    jt = date.today()  # 今天    # jt = date(2022, 9, 1) # 测试用    # 开始时间    start = jt - timedelta(days=1) # 昨天     # 开始日期月初日期    start_month_first = date(start.year, start.month, 1)    # 开始日期上月末日期    last_month_end = start_month_first - timedelta(days=1)        st = start.strftime(&#x27;%Y-%m-%d&#x27;)    et = last_month_end.strftime(&#x27;%Y-%m-%d&#x27;)    return st, et    st, et = riqi()riqi()\n例：9月26日，则返回9月25日和8月31日两个日期\n"},{"title":"用python如何读取10G的超大文件","url":"/2023/12/03/%E7%94%A8python%E5%A6%82%E4%BD%95%E8%AF%BB%E5%8F%9610G%E7%9A%84%E8%B6%85%E5%A4%A7%E6%96%87%E4%BB%B6/","content":"学习或者工作当中经常会碰到处理大文件的时候, 如果你只有一台普通电脑该如何处理呢? 今天跟大家分享一个处理技巧, 就算现在没有碰到, 点右上角先收藏说不定以后会用到呢!\n思路硬件条件有限, 我们可以试试用pandas分块读取, 读取文件后一般有3种处理办法:\n\n\n读取后拆分为多个小文件存放\n读取后筛选部分信息合并为一个文件\n对数据进行汇总(数据透视)后存储\n\n\n (解释: 比如原始数据是一个按时间的明细, 可以读取后按年或者按月保存问题; 这种大文件有时候列比较多, 但不一定都是我们需要的, 我们可以只筛选部分有用的列;  明细数据我们只使用一次, 需要的是汇总数据, 我们就可以透视后保存结果, 以后只读取结果数据即可)\n代码# 读取后保存为多个文件import pandas as pdfile = pd.read_csv(&#x27;./data/汇总表.csv&#x27;,iterator=True)  # iterator=True 表示分块读取n = 0while True:    chunk = file.get_chunk(5000000) # 每次读取500万条数据    chunk[[&#x27;pdf&#x27;, &#x27;fs&#x27;, &#x27;ey&#x27;,&#x27;nd&#x27;]].to_hdf(str(n)+&#x27;_data.h5&#x27;,key=&#x27;xy&#x27;) # 筛选部分列保存为hdf文件格式    print(chunk.tail(10))    n = n +1\n\n# 读取后合并为一个文件file = pd.read_csv(&#x27;./data/汇总表.csv&#x27;, iterator=True)loop = TruechunkSize = 1000000chunks = []while loop:    try:        chunk = reader.get_chunk(chunkSize)        chunks.append(chunk)    except StopIteration:        loop = False        print(&quot;读取完成&quot;)        df = pd.concat(chunks, ignore_index=True)  # 合并成一个文件\n"},{"title":"读取速度提升几倍","url":"/2023/12/03/%E8%AF%BB%E5%8F%96%E9%80%9F%E5%BA%A6%E6%8F%90%E5%8D%87%E5%87%A0%E5%80%8D/","content":"\n您好, 本博客将持续更新python数据分析技巧, 一次解决一个问题，欢迎关注订阅!\n\n本次介绍提升excel文件读取速度问题工作中我们会有一些大文件(excel, csv等),  作为基础数据经常会读取, 如何减少读取时间, 提升效率呢?\n今天用了一个88万行13列的表格, 按不同的方式读取比较读取用时如下:\n\nexcel文件: 文大小 61.9M, 读取用时 200秒\ncsv文件: 文件大小 194M, 读取用时 5秒\nhdf文件: 文件大小 80M, 读取用时 2秒\n\n相同的数据, 用hdf方式读取速度比其他两种快很多, 大文件建议不要存储为excel格式\n代码import pandas as pdimport timet1 = time.time()data_excel = pd.read_excel(&#x27;./data_excel.xlsx&#x27;)#data_csv = pd.read_csv(&#x27;./data_csv.csv&#x27;)#data_hdf= pd.read_hdf(&#x27;./data_hdf.h5&#x27;) # 文件路径也不能有中文t2 = time.time()print(&#x27;读取用时:&#x27;, t2 - t1)\n\ndataframe转hdf文件使用pandas.to_hdf()方法将dataframe转成后缀为h5的文件\ndata_csv.to_hdf(&#x27;./data_hdf.h5&#x27;,key=&#x27;xy&#x27;) # key参数为英文即可"}]